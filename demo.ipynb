{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yp5Nn7lzV3J6","colab_type":"text"},"source":["# Load pytorch library"]},{"cell_type":"code","metadata":{"id":"sZzTc_qcr0ge","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KtysNYMHV-XR","colab_type":"text"},"source":["# Define validation dataset ratio"]},{"cell_type":"code","metadata":{"id":"yO2LXvudAog6","colab_type":"code","colab":{}},"source":["\n","valid_ratio = 0.3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m77sHXmJWHfx","colab_type":"text"},"source":["# Define the MNIST training and validation sets, and possible transforms to be applied. Optional augmentation can be done within the transform. "]},{"cell_type":"code","metadata":{"id":"JNDByYIhr4TU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"7d9da354-5834-4d39-c685-c4facbb8bdab","executionInfo":{"status":"ok","timestamp":1575485242910,"user_tz":360,"elapsed":8419,"user":{"displayName":"Michael Wisnewski","photoUrl":"","userId":"08288731010122458134"}}},"source":["transform = transforms.Compose(\n","    [\n","    #  transforms.RandomRotation(degrees=30),\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.1307,), (0.3081,))])\n","\n","train_valid_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n","                                        download=True, transform=transform)\n","nb_train = int((1.0 - valid_ratio) * len(train_valid_dataset))\n","nb_valid =  int(valid_ratio * len(train_valid_dataset))\n","train_dataset, valid_dataset = torch.utils.data.dataset.random_split(train_valid_dataset, [nb_train, nb_valid])\n","trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=500, shuffle=True)\n","validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=500, shuffle=True)\n","\n","classes = ('0', '1', '2', '3',\n","           '4', '5', '6', '7', '8', '9')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:02, 3542115.02it/s]                            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"],"name":"stdout"},{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 55476.80it/s]                           \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:01, 940772.81it/s]                             \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["8192it [00:00, 21382.03it/s]            "],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"bEynLBaxWrnQ","colab_type":"text"},"source":["# Visualize the MNIST dataset."]},{"cell_type":"code","metadata":{"id":"EO8X36thsFKF","colab_type":"code","outputId":"457b2fd6-b6a9-4969-ad7a-6039b433e864","colab":{"base_uri":"https://localhost:8080/","height":192},"executionInfo":{"status":"ok","timestamp":1575485243349,"user_tz":360,"elapsed":8415,"user":{"displayName":"Michael Wisnewski","photoUrl":"","userId":"08288731010122458134"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# functions to show an image\n","\n","\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images[:4,]))\n","# print labels\n","print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXYAAAB5CAYAAAAtfwoEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["    2     4     5     5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9CUKf7kcW3Rh","colab_type":"text"},"source":["# Construct the CNN."]},{"cell_type":"code","metadata":{"id":"LOsjlBUKsbTF","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(32 * 7 * 7, 512)\n","        self.fc2 = nn.Linear(512, 128)\n","        self.fc3 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = F.relu(self.conv3(x))\n","        x = x.view(-1, 32 * 7 * 7)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_FC-AEZXXJE4","colab_type":"text"},"source":["# Instantiate the CNN and print out the number of parameters."]},{"cell_type":"code","metadata":{"id":"ghak7OKCXXpK","colab_type":"code","outputId":"b151f9a0-4ba9-498c-db97-07d37855b549","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["net = Net()\n","print(sum([p.numel() for p in net.parameters()]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["884330\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"slDGVTtkXd-Z","colab_type":"text"},"source":["# Define the loss function and the optimizer."]},{"cell_type":"code","metadata":{"id":"ml4xvTi7sgCE","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.01)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M9WLDB1R0CnA","colab_type":"text"},"source":["# Select the device to train the CNN! \"cuda:0\" means the first GPU device."]},{"cell_type":"code","metadata":{"id":"W90Lsx16swAe","colab_type":"code","outputId":"97e62b88-5500-4214-ddfd-6d4838522e86","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","net.to(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (fc1): Linear(in_features=1568, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"La3a6S81YSWs","colab_type":"text"},"source":["# Mount your google drive to current virtual machine. And define the path to store the trained CNN parameters."]},{"cell_type":"code","metadata":{"id":"zwLWBzgOuYZW","colab_type":"code","outputId":"64620603-12c4-497a-e3ab-ece2f7a64269","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","PATH = 'drive/My Drive/ML19/mnist_net.pth'\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8dLwz9XsYkNJ","colab_type":"text"},"source":["# Train the CNN and store the best model based on the validation loss."]},{"cell_type":"code","metadata":{"id":"csCvcF7Ss1Ud","colab_type":"code","colab":{}},"source":["import time\n","\n","start_time = time.time()\n","best_loss = np.float('inf')\n","for epoch in range(10):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    epoch_loss = running_loss / (i+1)\n","    print(\"Epoch: \", epoch, \" train loss: \", '%.3f' % epoch_loss)\n","    with torch.no_grad(): \n","      running_loss = 0.0\n","      for i, data in enumerate(validloader, 0):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data[0].to(device), data[1].to(device)\n","\n","          # forward \n","          outputs = net(inputs)\n","          loss = criterion(outputs, labels)\n","\n","          # print statistics\n","          running_loss += loss.item()\n","      epoch_loss = running_loss / (i+1)\n","      print(\"Epoch: \", epoch, \" validation loss: \", '%.3f' % epoch_loss)\n","      if epoch_loss < best_loss:\n","        torch.save(net.state_dict(), PATH)\n","        best_loss = epoch_loss\n","\n","time_elap = (time.time() - start_time) // 60\n","print('Finished Training in %d mins' % time_elap)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yfvPe-jSYsrR","colab_type":"text"},"source":["# Define the test dataset."]},{"cell_type":"code","metadata":{"id":"UQSOIHv7yf-3","colab_type":"code","colab":{}},"source":["transform = transforms.Compose(\n","     [transforms.ToTensor(),\n","     transforms.Normalize((0.1307,), (0.3081,))])\n","testset = torchvision.datasets.MNIST(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                         shuffle=False, num_workers=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4nqrJcR2Yzs5","colab_type":"text"},"source":["# Visualize the test dataset."]},{"cell_type":"code","metadata":{"id":"TqvrOr83y2B1","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","    \n","dataiter = iter(testloader)\n","images, labels = dataiter.next()\n","\n","# print images\n","imshow(torchvision.utils.make_grid(images))\n","print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l8DMyi8-Y4nB","colab_type":"text"},"source":["# Load the learned CNN parameters. This is required when you have trained the CNN and do no want to train it again by loading the learned parameters."]},{"cell_type":"code","metadata":{"id":"QTELpZUNy5yV","colab_type":"code","outputId":"9bd10573-26d0-492c-9a0b-edd7c4231b3b","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["net.load_state_dict(torch.load(PATH))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"fL7bMIiyZeFr","colab_type":"text"},"source":["# Get the predictions for the first 4 images in the test dataset."]},{"cell_type":"code","metadata":{"id":"lQeFNxLTzBxN","colab_type":"code","outputId":"8f02f942-0b8f-4275-d512-ac6a3b252a24","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["with torch.no_grad():\n","  outputs = net(images.to(device))\n","  _, predicted = torch.max(outputs, 1)\n","\n","print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n","                              for j in range(4)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Predicted:      7     2     1     0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3r7FPw9MZoMB","colab_type":"text"},"source":["# Infer on the whole test dataset."]},{"cell_type":"code","metadata":{"id":"F246Hc0QzLLV","colab_type":"code","outputId":"20088d32-8d83-47cf-d23c-377b2c8836a0","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n","                                         shuffle=False, num_workers=1)\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net(images.to(device))\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels.to(device)).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %.3F %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 98.430 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JOZILCzoZyQC","colab_type":"text"},"source":["# check the GPU device assigned by Google."]},{"cell_type":"code","metadata":{"id":"SYHUVXeezVx2","colab_type":"code","outputId":"db681901-8ab4-4376-ce4a-7449b1ab6a4f","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","import subprocess\n","print(subprocess.getoutput('nvidia-smi'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fri Nov 15 19:46:41 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   57C    P0    63W / 149W |    541MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]}]}